{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lhvHZYSB1Z2m"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3098943562.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i in range(1,2:\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import qadence\n",
    "import graphviz\n",
    "import numpy as np\n",
    "from qadence import feature_map, exp_fourier_feature_map, hea, chain, kron, operations, add\n",
    "from qadence import QNN, QuantumCircuit, Z, RY, RX\n",
    "from qadence.types import BasisSet, ReuploadScaling\n",
    "from qadence.draw import display\n",
    "\n",
    "for i in range(1,2:\n",
    "    \n",
    "    torch.manual_seed(i)\n",
    "    \n",
    "    # Mean-squared error as the comparison criterion\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Define the loss function\n",
    "    def loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Loss function encoding the problem to solve.\"\"\"\n",
    "        # Equation loss\n",
    "        model_output = model(inputs)\n",
    "        # Get the first order derivatives for both x and y\n",
    "        grads = torch.autograd.grad(model_output, inputs, grad_outputs=torch.ones_like(model_output), create_graph=True, retain_graph=True)[0]\n",
    "        f_m_x, f_m_y = grads[:,0], grads[:,1]\n",
    "        # Get the second order derivatives for both x and y\n",
    "        grads_x = torch.autograd.grad(f_m_x, inputs, grad_outputs=torch.ones_like(f_m_x), create_graph=True)[0]\n",
    "        f_m_x_x = grads_x[:,0]\n",
    "        grads_y = torch.autograd.grad(f_m_y, inputs, grad_outputs=torch.ones_like(f_m_y), create_graph=True)[0]\n",
    "        f_m_y_y = grads_y[:,1]\n",
    "        deriv_model = f_m_x_x + f_m_y_y\n",
    "        deriv_exact = torch.zeros_like(deriv_model)\n",
    "        pde_loss = criterion(deriv_model, deriv_exact) #MSE between derivative of models func and exact func\n",
    "    \n",
    "        # Boundary losses: \n",
    "        #   f(0,y) = sin(pi*y)\n",
    "        #   f(x,0) = 0\n",
    "        #   f(1,y) = exp(-pi)*sin(pi*y)\n",
    "        #   f(x,1) = 0\n",
    "        x=torch.rand(10)\n",
    "        y=torch.rand(10)\n",
    "        zeros = torch.zeros(10)\n",
    "        ones = torch.ones(10)\n",
    "    \n",
    "        all_coords = [torch.stack((zeros, y)),\n",
    "                  torch.stack((x, zeros)),\n",
    "                  torch.stack((ones, y)),\n",
    "                  torch.stack((x, ones))]\n",
    "        \n",
    "        bounds = [torch.sin(torch.pi*y),\n",
    "                  zeros,\n",
    "                  torch.exp(-torch.pi*ones)*torch.sin(torch.pi*y),\n",
    "                  zeros]\n",
    "        \n",
    "        tot_boundary_losses = 0\n",
    "        for i,(coords,boundary_exact) in enumerate(zip(all_coords,bounds)):\n",
    "            boundary_model = model(coords.T)\n",
    "            boundary_loss = criterion(boundary_model, boundary_exact)\n",
    "            tot_boundary_losses += boundary_loss\n",
    "        \n",
    "        return 0.01*pde_loss + tot_boundary_losses\n",
    "    \n",
    "    \n",
    "    # Begin creating the QNN\n",
    "    n_qubits = 6\n",
    "    \n",
    "    # Feature map\n",
    "    from sympy import atan, Function\n",
    "    \n",
    "    fm_x = feature_map(\n",
    "    n_qubits = 6,\n",
    "    param = \"x\",\n",
    "    fm_type = atan,\n",
    "    reupload_scaling = ReuploadScaling.EXP,\n",
    "    )\n",
    "    \n",
    "    fm_y = feature_map(\n",
    "        n_qubits = 6,\n",
    "        param = \"y\",\n",
    "        op = RY,\n",
    "        fm_type = BasisSet.FOURIER,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Entangling hardware-efficiency ansatz\n",
    "    from qadence import Strategy\n",
    "    \n",
    "    ansatz = hea(\n",
    "        n_qubits,\n",
    "        depth=depth,\n",
    "        strategy=Strategy.SDAQC\n",
    "    )\n",
    "    \n",
    "    from qadence.constructors import identity_initialized_ansatz\n",
    "    from qadence.draw import display\n",
    "    from qadence import hamiltonian_factory, Interaction, N, Register, hea\n",
    "    \n",
    "    register = Register.honeycomb_lattice(1, 1)\n",
    "    \n",
    "    entangler = hamiltonian_factory(\n",
    "        register,\n",
    "        interaction=Interaction.NN,\n",
    "        detuning=N,\n",
    "        interaction_strength=\"e\",\n",
    "        detuning_strength=\"n\"\n",
    "    )\n",
    "    \n",
    "    # Build a fully parameterized Digital-Analog HEA:\n",
    "    n_qubits = register.n_qubits\n",
    "    depth = 2\n",
    "    \n",
    "    \n",
    "    # Ansatz\n",
    "    ansatz = hea(\n",
    "        n_qubits=register.n_qubits,\n",
    "        depth=depth,\n",
    "        operations=[RX, RY, RX],\n",
    "        entangler=entangler,\n",
    "        strategy=Strategy.SDAQC\n",
    "    )\n",
    "    \n",
    "    # Observable\n",
    "    observable = Z(0) + 0.5*operations.I(1)\n",
    "    \n",
    "    circuit = QuantumCircuit(n_qubits, chain(fm_x, fm_y, ansatz))\n",
    "    model = QNN(circuit = circuit, observable = observable, inputs = [\"x\", \"y\"])\n",
    "    \n",
    "    #Begin training the model\n",
    "    n_epochs = 200\n",
    "    n_points = 70\n",
    "    \n",
    "    xmin = 0.01\n",
    "    xmax = 0.99\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Training data. A grid of points between 0 and 1 for both dimensions. We unsqueeze essentially making each batch have a single x value.\n",
    "        xy_train = (xmin + (xmax-xmin)*torch.rand(n_points, 2, requires_grad = True))\n",
    "    \n",
    "        loss = loss_fn(inputs = xy_train, model = model)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "        \n",
    "    def f_exact(xy: torch.Tensor) -> torch.Tensor:\n",
    "        x, y = xy[:,0], xy[:,1]\n",
    "        exp_x = torch.exp(-torch.pi * x)\n",
    "        sin_y = torch.sin(torch.pi * y)\n",
    "        return (exp_x * sin_y)\n",
    "        \n",
    "    # Grid of 2d points \n",
    "    x_test = torch.arange(xmin, xmax, step = 0.01)\n",
    "    y_test = torch.arange(xmin, xmax, step = 0.01)\n",
    "    meshx, meshy = torch.meshgrid(x_test,y_test)\n",
    "    xy_test = torch.stack((meshx.flatten(), meshy.flatten()), dim=1)\n",
    "    \n",
    "    result_exact = f_exact(xy_test).flatten()\n",
    "    result_model = model(xy_test).flatten().detach()\n",
    "    \n",
    "    ## SCORE\n",
    "    \n",
    "    n_points_1d = 100 # Use a grid of 100x100\n",
    "    # Create a length = 10.000 tensor of the (x, y) coordinates between 0 and 1\n",
    "    domain_1d = torch.linspace(0, 1.0, steps = n_points_1d)\n",
    "    domain = torch.cartesian_prod(domain_1d, domain_1d)\n",
    "    # Getting the exact solution and the DQC solution\n",
    "    exact_sol = f_exact(domain).reshape(n_points_1d, n_points_1d).T\n",
    "    dqc_sol = model(domain).reshape(n_points_1d, n_points_1d).T.detach()\n",
    "    # Mean Squared Error as the comparison criterion\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # Final score, the lower the better\n",
    "    score = criterion(dqc_sol, exact_sol)\n",
    "    # score.abs().item()\n",
    "    print(\"Score is: \", score)\n",
    "    \n",
    "    ## VISUALIZATION\n",
    "    \n",
    "    reshaped_model = result_model.reshape((len(x_test),len(x_test))).detach().numpy()\n",
    "    reshaped_exact = result_exact.reshape((len(x_test),len(x_test))).detach().numpy()\n",
    "    \n",
    "    # Plot the exact and the model solutions side by side in 3D\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    X, Y = torch.meshgrid(x_test, y_test)\n",
    "    ax1.plot_surface(X, Y, reshaped_model, cmap='rainbow')\n",
    "    ax1.set_title('Model solution')\n",
    "    ax2.plot_surface(X, Y, reshaped_exact, cmap='rainbow')\n",
    "    ax2.set_title('Exact solution')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the heatmap with color scale\n",
    "    fig2 = plt.figure(figsize=(10, 4))\n",
    "    ax3 = fig2.add_subplot(121)\n",
    "    ax4 = fig2.add_subplot(122)\n",
    "    heatmap = ax3.imshow(reshaped_model, cmap='rainbow', aspect='auto')\n",
    "    plt.colorbar(heatmap, label='Z')  # Add color bar with label\n",
    "    ax4.set_title('Model solution')\n",
    "    ax3.set_xlabel('X')\n",
    "    ax3.set_ylabel('Y')\n",
    "    heatmap = ax4.imshow(reshaped_exact, cmap='rainbow', aspect='auto')\n",
    "    plt.colorbar(heatmap, label='Z')  # Add color bar with label\n",
    "    ax4.set_title('Model solution')\n",
    "    ax4.set_xlabel('X')\n",
    "    ax4.set_ylabel('Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gbw8Ckxd-Qtl",
    "outputId": "3be6f48b-ecdb-4eb9-fa47-84a3dc24fd61"
   },
   "outputs": [],
   "source": [
    "# # 1D Evaluation Code\n",
    "# n_points_1d = 100 # Use a grid of 100x100\n",
    "# # Create a length = 10.000 tensor of the (x, y) coordinates between 0 and 1\n",
    "# domain_1d = torch.linspace(0, 1.0, steps = n_points_1d)\n",
    "# domain = torch.tensor(list(domain_1d))\n",
    "# # The exact solution for the Laplace equation\n",
    "# def exact_ode(domain: torch.Tensor):\n",
    "#     x = domain\n",
    "#     return x**4 + (1/3)*x**3 - x**2 - 0.5*x + 10\n",
    "\n",
    "# # Getting the exact solution and the DQC solution\n",
    "# exact_sol = exact_ode(domain).T #.reshape(n_points_1d, n_points_1d).T\n",
    "# dqc_sol = model(domain).T.detach()\n",
    "# # Mean Squared Error as the comparison criterion\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# # Final score, the lower the better\n",
    "# score = criterion(dqc_sol, exact_sol)\n",
    "# print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n",
    "#     grad = torch.autograd.grad(\n",
    "#         outputs=outputs,\n",
    "#         inputs=inputs,\n",
    "#         grad_outputs = torch.ones_like(inputs),\n",
    "#         create_graph = True,\n",
    "#         retain_graph = True,\n",
    "#     )[0]\n",
    "#     return grad\n",
    "\n",
    "# Mean-squared error as the comparison criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Loss function encoding the problem to solve.\"\"\"\n",
    "    # Equation loss\n",
    "    model_output = model(inputs)\n",
    "    # Get the first order derivatives for both x and y\n",
    "    grads = torch.autograd.grad(model_output, inputs, grad_outputs=torch.ones_like(model_output), create_graph=True, retain_graph=True)[0]\n",
    "    f_m_x, f_m_y = grads[:,0], grads[:,1]\n",
    "    \n",
    "    # Get the second order derivatives for both x and y\n",
    "    grads_x = torch.autograd.grad(f_m_x, inputs, grad_outputs=torch.ones_like(f_m_x), create_graph=True)[0]\n",
    "    f_m_x_x = grads_x[:,0]\n",
    "    grads_y = torch.autograd.grad(f_m_y, inputs, grad_outputs=torch.ones_like(f_m_y), create_graph=True)[0]\n",
    "    f_m_y_y = grads_y[:,1]\n",
    "    deriv_model = f_m_x_x + f_m_y_y\n",
    "    deriv_exact = torch.zeros_like(deriv_model)\n",
    "    pde_loss = criterion(deriv_model, deriv_exact) #MSE between derivative of models func and exact func\n",
    "    # print(pde_loss)\n",
    "    # Boundary losses: \n",
    "    #   f(0,y) = sin(pi*y)\n",
    "    #   f(x,0) = 0\n",
    "    #   f(1,y) = exp(-pi)*sin(pi*y)\n",
    "    #   f(x,1) = 0\n",
    "    x=torch.rand(10)\n",
    "    y=torch.rand(10)\n",
    "    zeros = torch.zeros(10)\n",
    "    ones = torch.ones(10)\n",
    "\n",
    "    all_coords = [torch.stack((zeros, y)),\n",
    "              torch.stack((x, zeros)),\n",
    "              torch.stack((ones, y)),\n",
    "              torch.stack((x, ones))]\n",
    "    \n",
    "    # for t in all_coords:\n",
    "    #     print(t.size())\n",
    "    \n",
    "    bounds = [torch.sin(torch.pi*y),\n",
    "              zeros,\n",
    "              torch.exp(-torch.pi*ones)*torch.sin(torch.pi*y),\n",
    "              zeros]\n",
    "\n",
    "    # for t in bounds:\n",
    "    #     print(t.size())\n",
    "    \n",
    "    tot_boundary_losses = 0\n",
    "    for i,(coords,boundary_exact) in enumerate(zip(all_coords,bounds)):\n",
    "        boundary_model = model(coords.T)\n",
    "        # print(boundary_model)\n",
    "        # if i == 0:\n",
    "        #     boundary_loss = 0.001*criterion(boundary_model, boundary_exact)\n",
    "        # else:\n",
    "        #     boundary_loss = 5*criterion(boundary_model, boundary_exact)\n",
    "        boundary_loss = criterion(boundary_model, boundary_exact)\n",
    "        # print(boundary_loss)\n",
    "        # tot_boundary_losses += boundary_loss**2\n",
    "        tot_boundary_losses += boundary_loss\n",
    "    sqrt_tot_boundary_losses = torch.sqrt(tot_boundary_losses)\n",
    "    \n",
    "    return 0.01*pde_loss + tot_boundary_losses\n",
    "\n",
    "from qadence import feature_map, exp_fourier_feature_map, hea, chain, kron, operations, add\n",
    "from qadence import QNN, QuantumCircuit, Z, RY, RX\n",
    "from qadence.types import BasisSet, ReuploadScaling\n",
    "from qadence.draw import display\n",
    "\n",
    "n_qubits = 6\n",
    "depth = 3\n",
    "\n",
    "# Feature map\n",
    "# fm_x = feature_map(\n",
    "#     n_qubits = 3,\n",
    "#     param = \"x\",\n",
    "#     fm_type = BasisSet.CHEBYSHEV,\n",
    "#     reupload_scaling = ReuploadScaling.EXP,\n",
    "#     support = (0, 1, 2)\n",
    "# )\n",
    "# fm_y = feature_map(\n",
    "#     n_qubits = 3,\n",
    "#     param = \"y\",\n",
    "#     op = RY,\n",
    "#     fm_type = BasisSet.FOURIER,\n",
    "#     support = (3, 4, 5)\n",
    "# )\n",
    "\n",
    "from sympy import atan, Function\n",
    "\n",
    "fm_x = feature_map(\n",
    "n_qubits = 6,\n",
    "param = \"x\",\n",
    "fm_type = atan,\n",
    "reupload_scaling = ReuploadScaling.EXP,\n",
    ")\n",
    "\n",
    "fm_y = feature_map(\n",
    "    n_qubits = 6,\n",
    "    param = \"y\",\n",
    "    op = RY,\n",
    "    fm_type = BasisSet.FOURIER,\n",
    ")\n",
    "display(chain(fm_x, fm_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
